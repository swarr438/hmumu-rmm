{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarr438/hmumu-rmm/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03vVx0mDtuwN"
      },
      "outputs": [],
      "source": [
        "# Check GPU configuration\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-hYfYhLSimI"
      },
      "source": [
        "#Enviroment Building#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6lQWMdbSxJ8"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip --quiet\n",
        "# !pip install --upgrade numpy==1.24 --quiet\n",
        "!pip install --upgrade matplotlib --quiet\n",
        "!pip install --upgrade torchaudio torch==2.1.0  torchvision --quiet\n",
        "!pip install tensorboard --quiet\n",
        "\n",
        "!pip install torchmetrics --quiet\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhQS1zEqSchW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import models\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfBHx8X3UzPO"
      },
      "outputs": [],
      "source": [
        "# Load datasets from Google Drive\n",
        "# or you can upload them manually\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEw_UxxEWQa1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Extract datasets\n",
        "\n",
        "Path_of_folder = '/content/drive/MyDrive/dataset/rmm/' # @param {type:\"string\"}\n",
        "Filename = 'dataset_f.zip' # @param {type:\"string\"}\n",
        "pathdata = Path_of_folder+Filename\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(pathdata, 'r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz2SviTkY96l"
      },
      "source": [
        "#Model Config#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj4q4aaqY9YG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Dataset Class\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image\n",
        "\n",
        "'''Datasets & dataloaders'''\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None, target_transform=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            img_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.img_labels = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPRXsvSeXvvV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy.sql.selectable import SelectLabelStyle\n",
        "#@title Dataset Loader\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "training_data = ImageDataset(csv_file='dataset0.csv',img_dir='./dataset0/',transform=transform)\n",
        "validation_data = ImageDataset(csv_file='dataset1.csv',img_dir='./dataset1/',transform=transform)\n",
        "test_data = ImageDataset(csv_file='dataset2.csv',img_dir='./dataset2/',transform=transform)\n",
        "# val_data3 = ImageDataset(csv_file='dataset3.csv',img_dir='./dataset3/',transform=transform)\n",
        "# val_data4 = ImageDataset(csv_file='dataset4.csv',img_dir='./dataset4/',transform=transform)\n",
        "'''\n",
        "training_data = ImageDataset(csv_file='dataset5.csv',img_dir='./dataset5/',transform=transform)\n",
        "validation_data = ImageDataset(csv_file='dataset7.csv',img_dir='./dataset7/',transform=transform)\n",
        "test_data = ImageDataset(csv_file='dataset6.csv',img_dir='./dataset6/',transform=transform)\n",
        "'''\n",
        "batch_size=4096\n",
        "num_workers=2\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=batch_size,\n",
        "                          shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(validation_data, batch_size=batch_size,\n",
        "                        shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size,\n",
        "                         shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "# val_loader3 = DataLoader(val_data3, batch_size=batch_size,\n",
        "#                         shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "# val_loader4 = DataLoader(val_data4, batch_size=batch_size,\n",
        "#                         shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "global classes\n",
        "classes = ('bkg','sig')#('bkg','ttH','VH','VBF','ggF')##('bkg','VH','ggF')\n",
        "\n",
        "def subload(dataloader):\n",
        "  dataset = dataloader.dataset\n",
        "  select = list(range(0,len(dataset),10))\n",
        "  subs = Subset(dataset, select)\n",
        "  sub_loader = DataLoader(subs, batch_size=4096, shuffle=True,\n",
        "                          num_workers=0,pin_memory=True)\n",
        "  return sub_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrTTvcdAbb09",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Initialize the ResNet Model\n",
        "\n",
        "num_classes = 2 #@param{type:'integer'}\n",
        "\n",
        "model = models.resnet18(weights=None)#'ResNet18_Weights.DEFAULT')\n",
        "model.fc = nn.Linear(512, out_features=num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "FOUND_LR = 1e-3\n",
        "\n",
        "params = [\n",
        "          {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
        "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
        "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
        "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
        "          {'params': model.fc.parameters()}\n",
        "         ]\n",
        "\n",
        "#optimizer = torch.optim.Adam(params, lr = FOUND_LR)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=FOUND_LR, momentum=0.8)\n",
        "\n",
        "MAX_LRS = [p['lr'] for p in optimizer.param_groups]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHt1iffXcLeC"
      },
      "source": [
        "#Training#"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Functions\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "!mkdir models\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def testpf(loader):\n",
        "   # corresponding test performance\n",
        "   model.eval()\n",
        "   with torch.no_grad():\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            total += labels.size(0)\n",
        "            losst = criterion(outputs, labels)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        return losst.item(), total, 100*correct/total\n",
        "\n",
        "def train(train_loader, test_loader, criterion, optimizer, scheduler,\n",
        "          n_epochs=50, start_epoch=0):\n",
        "  writer = SummaryWriter()\n",
        "  nstep = 0\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.monotonic()\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # move images and labels to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        model.train()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        nstep+=1\n",
        "        #scheduler.step()\n",
        "\n",
        "    lossa, ta, crta = testpf(train_loader)\n",
        "    losst, tt, crtt = testpf(test_loader)\n",
        "    total_epoch = start_epoch+epoch\n",
        "    writer.add_scalars('Loss', {'train':lossa,'test':losst}, total_epoch)\n",
        "    writer.add_scalars('Accuracy', {'train':crta,'test':crtt}, total_epoch)\n",
        "    writer.flush()\n",
        "\n",
        "    scheduler.step(losst)\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print('Epoch [{}/{}], {}m {}s, Loss: {:.4f}, '\n",
        "                   .format(total_epoch+1, start_epoch+n_epochs,\n",
        "                           epoch_mins, epoch_secs,\n",
        "                           loss.item()))\n",
        "    print('Accuracy of the network on the {} test images: {} %'\n",
        "                   .format(tt, crtt))\n",
        "\n",
        "    # autosave\n",
        "    PATH = f\"/content/models/{total_epoch+1}.pt\"\n",
        "    if (epoch+1)%10==0:\n",
        "      torch.save({\n",
        "              'epoch': total_epoch+1,\n",
        "              'model': model.state_dict(),\n",
        "              'optimizer': optimizer.state_dict(),\n",
        "              'lr':  [ group['lr'] for group in optimizer.param_groups ],\n",
        "              'loss': loss\n",
        "              }, PATH)\n",
        "\n",
        "  writer.close()\n",
        "  return total_epoch, loss"
      ],
      "metadata": {
        "id": "b0WwLxvWWOS8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.inputtransformer2 import show_linewise_tokens\n",
        "#@title Check Datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "shown = 16\n",
        "imshow(torchvision.utils.make_grid(images[:shown]))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(shown)))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H8l9V0YlgD2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29jQ_T0wcLDh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Process\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=runs\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR\n",
        "\n",
        "n_epochs = 30 # @param{type:'integer'}\n",
        "#@markdown For resuming, load the checkpoint first\n",
        "resume = False #@param{type:\"boolean\"}\n",
        "start_epoch = 0\n",
        "if resume:\n",
        "  try:\n",
        "    start_epoch = epoch\n",
        "  except NameError:\n",
        "    start_epoch = 0\n",
        "\n",
        "EPOCHS = n_epochs\n",
        "STEPS_PER_EPOCH = len(train_loader)\n",
        "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
        "\n",
        "# scheduler = OneCycleLR(optimizer, max_lr = MAX_LRS,\n",
        "#                        total_steps = TOTAL_STEPS)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, cooldown=3,\n",
        "                              min_lr=1e-10)\n",
        "\n",
        "total_epoch, loss = train(test_loader, subload(train_loader),\n",
        "                          criterion, optimizer, scheduler,\n",
        "                          n_epochs, start_epoch=start_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAiRGMWbd6qc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Save or Load the Checkpoint from Google Drive\n",
        "\n",
        "\n",
        "ckpt_name  = 'rmm_f2.pt' # @param{type:\"string\"}\n",
        "PATH = Path_of_folder+ckpt_name\n",
        "#@markdown Intialize the resnet model before loading\n",
        "load = False # @param {type:\"boolean\"}\n",
        "if not load:\n",
        "  epoch = start_epoch + n_epochs\n",
        "  torch.save({\n",
        "              'epoch': epoch,#total_epoch+1,\n",
        "              'model': model.state_dict(),\n",
        "              'optimizer': optimizer.state_dict(),\n",
        "              'lr': [ group['lr'] for group in optimizer.param_groups ],\n",
        "              'loss': loss\n",
        "              }, PATH)\n",
        "else:\n",
        "  checkpoint = torch.load(PATH)\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation#"
      ],
      "metadata": {
        "id": "63e0buW7nBhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "def score(model,loader,num_classes=2):\n",
        "     with torch.no_grad():\n",
        "        model.eval()\n",
        "        real_res = torch.zeros(len(loader.dataset), dtype=torch.long)\n",
        "        pred_res = torch.zeros(len(loader.dataset), num_classes)\n",
        "        i = 0\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            interval = len(labels)\n",
        "\n",
        "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            real_res[i:i+interval] = labels\n",
        "            pred_res[i:i+interval] = probs\n",
        "\n",
        "            i+=interval\n",
        "\n",
        "        # accuracy\n",
        "        thre_range = np.linspace(0,1,100)\n",
        "        acc = torch.zeros(len(thre_range), num_classes)\n",
        "        for k in range(len(thre_range)):\n",
        "          if num_classes!=2:\n",
        "            accuracy = torchmetrics.Accuracy(task=\"multiclass\",\n",
        "                                            num_classes=num_classes, average=None)\n",
        "            acc[k] = 100*accuracy(pred_res,real_res)\n",
        "          else:\n",
        "            accuracy = torchmetrics.Accuracy(task=\"binary\", threshold=thre_range[k])\n",
        "            acc[k][0] = 100*accuracy(pred_res[:,0],1-real_res)\n",
        "            acc[k][1] = 100*accuracy(pred_res[:,1],real_res)\n",
        "\n",
        "        accuracy = torchmetrics.Accuracy(task=\"multiclass\",\n",
        "                    num_classes=num_classes, average='macro')\n",
        "        ave_acc = 100*accuracy(pred_res,real_res)\n",
        "\n",
        "        print(f'Total Events: {i}')\n",
        "\n",
        "        # stat_scores = torchmetrics.StatScores(task=\"binary\", average=None)\n",
        "        # roc & f1 score\n",
        "        roc = torchmetrics.ROC(task=\"multiclass\",thresholds=100,num_classes=num_classes)\n",
        "        f1s = torchmetrics.F1Score(task=\"multiclass\",num_classes=num_classes,average=None)\n",
        "        f1sa = torchmetrics.F1Score(task=\"multiclass\",num_classes=num_classes,average='micro')\n",
        "\n",
        "        return roc(pred_res,real_res), torch.transpose(acc,0,1), ave_acc.item()"
      ],
      "metadata": {
        "id": "8PRLYBm-Kz71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc, acc, ave_acc = score(model,test_loader,num_classes=num_classes)\n",
        "\n",
        "fpr = roc[0].cpu().detach().numpy()\n",
        "tpr = roc[1].cpu().detach().numpy()\n",
        "thre = roc[2].cpu().detach().numpy()\n",
        "acc = acc.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "K0ttYhC1zIlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classindex = 1\n",
        "\n",
        "fig = plt.figure(figsize=plt.figaspect(0.4))\n",
        "\n",
        "if num_classes==2:\n",
        "  classes = ('bkg','sig')\n",
        "elif num_classes==5:\n",
        "  classes = ('bkg','ttH','VH','VBF','ggF')\n",
        "\n",
        "# 3d\n",
        "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "# for classindex in range(num_classes):\n",
        "ax.plot3D(fpr[classindex], tpr[classindex], thre, color='orange')\n",
        "ax.set_xlabel('FPR')\n",
        "ax.set_ylabel('TPR')\n",
        "ax.set_zlabel('Threshold')\n",
        "ax.set_box_aspect(aspect=None, zoom=0.8)\n",
        "\n",
        "# 2d\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "#for classindex in range(num_classes):\n",
        "auc = np.trapz(tpr[classindex],x=fpr[classindex])\n",
        "ax.plot(fpr[classindex],tpr[classindex], color='orange',\n",
        "        label=f'{classes[classindex]}, AUC = {auc:.2f}, Precision = {acc[classindex][50]:.1f}%')\n",
        "anx = fpr[classindex][50]\n",
        "any = tpr[classindex][50]\n",
        "ax.plot(anx, any,'o',color='red')\n",
        "\n",
        "ax.plot(anx, any,'o',color='red',label='Points at threshold = 0.5')\n",
        "\n",
        "ax.set_xlabel('FPR')\n",
        "ax.set_ylabel('TPR')\n",
        "plt.title('ROC Curve')\n",
        "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "ax.text(0.05, 0.95, '$\\mathrm{Accuracy}='+'{:.2f}\\%$'.format(ave_acc), transform=ax.transAxes, fontsize=14,\n",
        "        verticalalignment='top', bbox=props)\n",
        "\n",
        "# dashed line\n",
        "ax.plot(np.linspace(0,1),np.linspace(0,1),'--',color='k')\n",
        "lp = np.array((.5, .5))\n",
        "th2 = ax.text(*lp, 'Random classifier', horizontalalignment='center',\n",
        "              verticalalignment='center', color='k',\n",
        "              fontsize=12, rotation=45, rotation_mode='anchor',\n",
        "              transform_rotates_text=True)\n",
        "# ax.annotate('$\\mathrm{Threshold}=0.5$\\n$\\mathrm{Accuracy}='+'{:.2f}\\%$'.format(acc[classindex][49]),\n",
        "#             color='red', xy=(anx, any), xytext=(anx-0.45, any-0.05))\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qSir23wGAQvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.lines import lineStyles\n",
        "fig, ax = plt.subplots()\n",
        "classname = ['bkg','sig']\n",
        "for classindex in {1}:\n",
        "  accx=acc[classindex]\n",
        "  maxp = np.argmax(accx)\n",
        "  thre_range = np.linspace(0,1,len(accx))\n",
        "\n",
        "  ax.plot(thre_range, accx, color='orange', label=f'{classname[classindex]}')\n",
        "  ax.plot(thre_range[maxp],accx[maxp],'o',color='red')\n",
        "  ax.vlines(0.5,30,75,'k',linestyles='dashed')\n",
        "  ax.annotate('Max: ${:.2f}$'.format(accx[maxp]),xy=(thre_range[maxp],accx[maxp]),\n",
        "              xytext=(thre_range[maxp],accx[maxp]-3),color='red')\n",
        "  ax.set_xlabel('Threshold')\n",
        "  ax.set_ylabel('Accuracy(%)')\n",
        "\n",
        "#plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xeor80vjBda7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def decompose(loader, classindex):\n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      k = 0\n",
        "      for images, labels in loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "\n",
        "          _,preds = torch.max(outputs.data, 1)\n",
        "\n",
        "          for i, label in enumerate(labels):\n",
        "            if label==classindex:\n",
        "              pred = torch.unsqueeze(preds[i],0)\n",
        "              if k == 0:\n",
        "                x = pred\n",
        "              else:\n",
        "                x = torch.cat((x,pred),0)\n",
        "\n",
        "              k+=1\n",
        "\n",
        "      print(f\"{'label '+classes[classindex]:*^20}\")\n",
        "      x = x.cpu().detach().numpy()\n",
        "      for (nam,numb) in Counter(x).items():\n",
        "        namin = int(nam)\n",
        "        numb /= k\n",
        "        print(f'{classes[namin]}:{100*numb:.2f}%')\n",
        "\n",
        "for q in range(num_classes):\n",
        "  decompose(val_loader,q)\n",
        "  print('-'*30)\n"
      ],
      "metadata": {
        "id": "tgnKKhLNaY1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNqaXB0xduC4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyO3ik5LvAMRMYcg0zlSNAKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}